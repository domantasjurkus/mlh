{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-66e06fd1421a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss at alpha:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m \u001b[0mtest_regularisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-66e06fd1421a>\u001b[0m in \u001b[0;36mtest_regularisation\u001b[0;34m(X, PRP)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_regularisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mregularFactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation loss at alpha:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPRP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0mtest_regularisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-66e06fd1421a>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(trainX, traint, folds, regularFactor)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m#w = get_nr_weights(cv_trainX, cv_traint)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gd_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_trainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_traint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# Regularise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-66e06fd1421a>\u001b[0m in \u001b[0;36mget_gd_weights\u001b[0;34m(X, t, iterations, alpha, regularFactor)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m#allw = np.zeros((weight_count,iterations))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;31m#allw[:,i] = w.flatten()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mregularFactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msample_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msample_count\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#EPSILON=0.5\n",
    "\n",
    "# Datum\n",
    "trainX = np.loadtxt('X_train.csv', delimiter=',', skiprows=1)\n",
    "traint = np.loadtxt('y_train.csv', delimiter=',', skiprows=1)\n",
    "traint = traint[:,1][:,None]-1\n",
    "\n",
    "testX = np.loadtxt('X_test.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "\"\"\"def plot_pair(X, t, f1, f2):\n",
    "    plt.figure()\n",
    "    pos0 = np.where(t==0)[0]\n",
    "    pos1 = np.where(t==1)[0]\n",
    "    plt.plot(X[pos1,f1], X[pos1,f2],'bo')\n",
    "    plt.plot(X[pos0,f1], X[pos0,f2],'ro')\"\"\"\n",
    "\n",
    "def save_predictions(predictions, filename=\"class_logit.csv\"):\n",
    "    N = predictions.shape[0]\n",
    "    output = np.ones((N, 2))\n",
    "    output[:,0] = range(N)\n",
    "    output[:,1] = predictions.ravel()\n",
    "    np.savetxt(filename, output, fmt='%d', delimiter=\",\", header=\"Id,EpiOrStroma\")\n",
    "    \n",
    "def to_binary(x):\n",
    "    if x < 0.5:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def h(x, w):\n",
    "    return sigmoid(np.dot(x, w))\n",
    "\n",
    "def sigmoid(x):\n",
    "    val = scipy.special.expit(x)\n",
    "    return val\n",
    "\n",
    "def cv(trainX, traint, folds=20, regularFactor=0):\n",
    "    sample_count = trainX.shape[0]\n",
    "    feature_count = trainX.shape[1]\n",
    "    fold_size = sample_count//folds\n",
    "    \n",
    "    average_accuracy = 0\n",
    "    \n",
    "    for i in range(folds):\n",
    "        split_index1 = i*fold_size\n",
    "        split_index2 = (i+1)*fold_size\n",
    "        \n",
    "        cv_testX = trainX[split_index1:split_index2]\n",
    "        cv_testt = traint[split_index1:split_index2]\n",
    "        cv_trainX = np.concatenate((trainX[:split_index1], trainX[split_index2:]))\n",
    "        cv_traint = np.concatenate((traint[:split_index1], traint[split_index2:]))\n",
    "        \n",
    "        #\n",
    "        # Homemade models\n",
    "        #        \n",
    "        #w = get_nr_weights(cv_trainX, cv_traint)\n",
    "        w = get_gd_weights(cv_trainX, cv_traint, 0.9, regularFactor)\n",
    "        \n",
    "        # Regularise\n",
    "        #w = np.identity(feature_count)\n",
    "        \n",
    "        predictions = np.array(list(map(to_binary, h(cv_testX, w))))[:,None]\n",
    "        #print(predictions)\n",
    "        \n",
    "        #\n",
    "        # Sklearn models\n",
    "        #\n",
    "        #model = get_sk_model(cv_trainX, cv_traint)\n",
    "        #predictions = model.predict(cv_testX)\n",
    "        #print(predictions[0:5])\n",
    "        #print(cv_testt[0:5])\n",
    "        \n",
    "        acc = get_accuracy(predictions, cv_testt)\n",
    "        average_accuracy += acc\n",
    "        #print(\"Iteration and accuracy:\", i, acc)\n",
    "    \n",
    "    print(\"Total accuracy:\", average_accuracy/folds)\n",
    "    return average_accuracy/folds\n",
    "    \n",
    "def get_accuracy(predictions, actual):\n",
    "    N = predictions.shape[0]\n",
    "    temp = predictions-actual\n",
    "    misses = np.count_nonzero(temp)\n",
    "    hits = N-misses\n",
    "    return hits/N\n",
    "        \n",
    "def make_predictions(X, w):\n",
    "    preds = np.zeros((X.shape[0], 1))\n",
    "    for i in range(X.shape[0]):\n",
    "        x = X[i]\n",
    "        preds[i] = to_binary(h(x, w))\n",
    "    return preds\n",
    "\n",
    "def filter_by_variance(trainX, keep_count=10):\n",
    "    sample_count = trainX.shape[0]\n",
    "    feature_count = trainX.shape[1]\n",
    "    variances = np.zeros(feature_count)\n",
    "    \n",
    "    # Find variance of each feature\n",
    "    for i in range(feature_count):\n",
    "        feature = trainX.T[i]\n",
    "        variance = np.var(feature)\n",
    "        variances[i] = variance    \n",
    "    \n",
    "    features_by_variance = variances.argsort()[:keep_count]\n",
    "\n",
    "    newX = np.zeros((sample_count, keep_count))\n",
    "    for i in range(keep_count):\n",
    "        newX[:,i] = trainX[:,features_by_variance[i]]\n",
    "\n",
    "    return newX, features_by_variance\n",
    "\n",
    "def get_sk_model(trainX, traint):\n",
    "    clf = LogisticRegression()\n",
    "    model = clf.fit(trainX, traint.ravel())\n",
    "    return model\n",
    "\n",
    "\"\"\"def predict_sklearn(model, testX):\n",
    "    predictions = model.predict(testX)\n",
    "    return predictions\"\"\"\n",
    "\n",
    "# Newton Raphson\n",
    "\"\"\"def get_nr_weights(trainx, traint, iterations=20):\n",
    "    n_weights = trainx.shape[1]\n",
    "    \n",
    "    w = np.zeros((n_weights,1))\n",
    "    dx = np.diag(np.dot(trainx, trainx.T))[:,None]\n",
    "    \n",
    "    # allw - for debugging\n",
    "    #allw = np.zeros((n_weights,iterations))\n",
    "\n",
    "    for i in range(iterations):\n",
    "        #allw[:,i] = w.flatten()\n",
    "        P = 1.0/(1.0 + np.exp(-np.dot(trainx, w)))\n",
    "        gw = -w + np.sum(trainx*np.tile(traint-P,(1,n_weights)), axis=0)[:,None]\n",
    "        temp = trainx*np.tile(P*(1-P), (1,n_weights))\n",
    "        hw = -np.eye(n_weights) - np.dot(temp.T, trainx)\n",
    "        w = w - np.dot(np.linalg.inv(hw), gw)\n",
    "    \n",
    "    return w\"\"\"\n",
    "\n",
    "# Gradient descent\n",
    "def get_gd_weights(X, t, iterations=5000, alpha=0.9, regularFactor=0):\n",
    "    sample_count = X.shape[0]\n",
    "    weight_count = X.shape[1]\n",
    "    w = np.zeros(weight_count)[:,None]\n",
    "    \n",
    "    # Plot\n",
    "    #allw = np.zeros((weight_count,iterations))\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        #allw[:,i] = w.flatten()\n",
    "        w = w*(1-(alpha*regularFactor)/sample_count) - alpha/sample_count * np.dot(X.T, h(X,w)-t)\n",
    "        \n",
    "        # Debug\n",
    "        #if i%10000 == 0: print(w[0:5].T, i)\n",
    "            \n",
    "        #print(\"Updated weights after iteration\", iters)\n",
    "\n",
    "#     [plt.plot(allw[w,:]) for w in range(weight_count)]\n",
    "#     plt.xlabel('Iteration')\n",
    "#     plt.ylabel('w')\n",
    "\n",
    "    return w\n",
    "\n",
    "# Filter by ttest\n",
    "#trainX, top_feature_indices = filter_by_ttest(trainX, traint, 25)\n",
    "trainX, top_feature_indices = filter_by_variance(trainX, 22)\n",
    "\n",
    "#w = get_nr_weights(trainX, traint)\n",
    "#w = get_gd_weights(trainX, traint, 300000, 0.9)\n",
    "\n",
    "\n",
    "\n",
    "# Single CV\n",
    "#cv(trainX, traint)\n",
    "\n",
    "# Loop CV to find subset of features\n",
    "# for feature_count in range(1, 112):\n",
    "#     newX, _ = filter_by_ttest(trainX, traint, feature_count)\n",
    "#     #newX, _ = filter_by_variance(trainX, feature_count)\n",
    "#     cv(newX, traint)\n",
    "\n",
    "def test_regularisation(X, PRP):\n",
    "    for regularFactor in [0, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        print(\"Validation loss at alpha:\", cv(X, PRP, 20, regularFactor), alpha)\n",
    "\n",
    "test_regularisation(trainX, traint)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_predictions(predictions, filename=\"classification_predictions.csv\"):\n",
    "    N = predictions.shape[0]\n",
    "    \n",
    "    output = np.ones((N, 2))\n",
    "    output[:,0] = range(N)\n",
    "    output[:,1] = predictions.ravel()\n",
    "    np.savetxt(filename, output, fmt='%d', delimiter=\",\", header=\"Id,EpiOrStroma\")\n",
    "    print(\"Predictions saved\")\n",
    "\n",
    "# Select only top features if filtered\n",
    "testX = testX[:,top_feature_indices]\n",
    "\n",
    "# Uncoment line below to predic w with logistical\n",
    "#preds = make_predictions(testX, w)\n",
    "\n",
    "# Uncomment block below to predict w with sklearn\n",
    "model = get_sk_model(trainX, traint)\n",
    "preds = model.predict(testX)\n",
    "\n",
    "# Save\n",
    "#save_predictions(preds+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
